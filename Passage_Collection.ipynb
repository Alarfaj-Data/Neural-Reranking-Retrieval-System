{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "omC6KJmE_k4z",
   "metadata": {
    "id": "omC6KJmE_k4z"
   },
   "outputs": [],
   "source": [
    "!pip install dask[dataframe] # More efficient than pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a82f17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63a82f17",
    "outputId": "a30106bb-f57b-49e7-cdcb-e098bdb5092a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "import csv\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\", \"tagger\", \"parser\", \"lemmatizer\", \"textcat\", \"attribute_ruler\"]) # loading the tokenizer \n",
    "nlp.max_length = 2500000\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "data_dir = '/content/drive/MyDrive/MSMARCO/'\n",
    "dir = '/content/drive/MyDrive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vTBgJkph-TCD",
   "metadata": {
    "id": "vTBgJkph-TCD"
   },
   "outputs": [],
   "source": [
    "# read the original collection file\n",
    "Collection = dd.read_csv(os.path.join(data_dir, 'msmarco-docs.tsv'), sep='\\t', header=None, usecols=['docid', 'doc_text'],\n",
    "                       names=['docid', 'url', 'title', 'doc_text']).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QMkgKCQbQU3H",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMkgKCQbQU3H",
    "outputId": "56de9619-f7d4-4424-e8f8-bebb5de45423"
   },
   "outputs": [],
   "source": [
    "Passage_Collection = []\n",
    "    \n",
    "for i in tqdm(range(len(Collection))):\n",
    "    new_doc_tokens = []\n",
    "    count = 0\n",
    "    tokens = nlp(str(Collection.iloc[i].doc_text)) # tokenize to get a list of tokens \n",
    "    for token in tokens:\n",
    "        if count == 500:\n",
    "            break\n",
    "        if token.is_space is False:\n",
    "            new_doc_tokens.append(token.text) # add tokens until reaching 500\n",
    "            count = count + 1\n",
    "    Passage_Collection.append([Collection.iloc[i].docid, ' '.join(new_doc_tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdffc98",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9bdffc98"
   },
   "outputs": [],
   "source": [
    "# Writing to disk\n",
    "columns=['docid','doc_text']\n",
    "with open(os.path.join(data_dir,'Passage_Collection.csv'), 'w', encoding=\"utf8\", newline='') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(columns)\n",
    "    write.writerows(Passage_Collection)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Passage Collection.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
