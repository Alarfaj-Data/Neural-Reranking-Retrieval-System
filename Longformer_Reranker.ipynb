{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjaCjJYN8-ax"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print('The GPU Assigned is:', torch.cuda.get_device_name(0)) # Tesla P100-PCIE-16GB is good, if assigned a different GPU, delete the runtime, and connect again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCVdijuj6puv"
   },
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "%pip install transformers\n",
    "%pip install python-terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLsYO6QTLPxj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset, SequentialSampler\n",
    "from transformers import LongformerTokenizer, LongformerForSequenceClassification\n",
    "from google.colab import drive\n",
    "import pyterrier as pt\n",
    "from pyterrier.measures import *\n",
    "\n",
    "# Initialize PyTerrier\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Directories\n",
    "DATA_DIR = '/content/drive/MyDrive/MSMARCO/'\n",
    "FULL_INDEX_DIR = '/content/drive/MyDrive/Full_Index/'\n",
    "PASSAGE_INDEX_DIR = '/content/drive/MyDrive/Passage_Index/'\n",
    "\n",
    "# Print GPU information\n",
    "print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "DEVICE = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dv1pW8W74-6l"
   },
   "outputs": [],
   "source": [
    "#Initilize tokenizer and model\n",
    "\n",
    "TOKENIZER = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "MODEL = LongformerForSequenceClassification.from_pretrained('/content/drive/MyDrive/Longformer_checkpoint2/', num_labels = 2) #Finetuned model\n",
    "MODEL.to(DEVICE) # Model to GPU\n",
    "MODEL.eval() # Evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtQEat8Ak5eH"
   },
   "outputs": [],
   "source": [
    "# This function handels the toknizer and returns TensorDataset to be fed to the model\n",
    "\n",
    "def tokenize(dataset, max_length=1024):\n",
    "    input_ids, attention_masks, global_attention_masks = [], [], []\n",
    "\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        encoded_dict = TOKENIZER.encode_plus(\n",
    "            str(dataset.iloc[i].query),  # Query\n",
    "            str(dataset.iloc[i].body),  # Document\n",
    "            add_special_tokens=True,  # Add '<s>' and '</s>'\n",
    "            max_length=max_length,  # Pad & truncate all sentences\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,  # Construct attn. masks\n",
    "            truncation='only_second',\n",
    "            return_tensors='pt'  # Return pytorch tensors\n",
    "        )\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "        global_attention = [0] * max_length\n",
    "        range_with_cls = len(nlp(dataset.iloc[i].query)) + 1\n",
    "        for j in range(range_with_cls):\n",
    "            global_attention[j] = 1\n",
    "        global_attention_masks.append(torch.tensor([global_attention]))\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    global_attention_masks = torch.cat(global_attention_masks, dim=0)\n",
    "\n",
    "    return TensorDataset(input_ids, attention_masks, global_attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-okrMbtoxEyU"
   },
   "outputs": [],
   "source": [
    "# Load MSMARCO dataset\n",
    "msmarco_dataset = pt.get_dataset(\"msmarco_document\")\n",
    "qrels = msmarco_dataset.get_qrels('test')\n",
    "topics = msmarco_dataset.get_topics('test')\n",
    "index = pt.IndexFactory.of(FULL_INDEX_DIR)\n",
    "index2 = pt.IndexFactory.of(PASSAGE_INDEX_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnjhK_nfxZlL"
   },
   "outputs": [],
   "source": [
    "# BM25 retrieval\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\", metadata=[\"title\", \"docno\", \"body\"]) % 200 # Retrieve only top 200 docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiG7cq3QHXQM"
   },
   "outputs": [],
   "source": [
    "def longformer(ranked_results, query_list_length, query=None, model=MODEL, device=DEVICE, batch_size=8):\n",
    "    ranked_results_tensor = tokenize(ranked_results)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        ranked_results_tensor,\n",
    "        sampler=SequentialSampler(ranked_results_tensor),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    pred_tensor = []\n",
    "    for batch in dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_global = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            result = model(\n",
    "                b_input_ids,\n",
    "                attention_mask=b_input_mask,\n",
    "                global_attention_mask=b_global,\n",
    "                return_dict=True\n",
    "            )\n",
    "\n",
    "        logits = result.logits\n",
    "        pred_tensor.append(logits)\n",
    "\n",
    "    pred = torch.cat(pred_tensor, 0)\n",
    "    prob = torch.sigmoid(pred)  # To get probabilities from logits (since we only have two labels, we use sigmoid)\n",
    "    prob_final = np.delete(prob.cpu().numpy(), 0, 1).flatten()  # Deletes first column with probability of not being relevant\n",
    "\n",
    "    for i in range(len(ranked_results)):\n",
    "        ranked_results.iloc[i, ranked_results.columns.get_loc('score')] = prob_final[i]\n",
    "\n",
    "    if query is not None:\n",
    "        ranked_results_list = []\n",
    "        for i in range(query_list_length):\n",
    "            df = ranked_results[ranked_results['qid'] == query.iloc[i].qid] # Extracting docs for each query to rank them\n",
    "            df = df.sort_values(by=['score'], ascending=False) # Sorting by score\n",
    "            df = df.values.tolist()\n",
    "            for p in range(len(df)):\n",
    "                df[p][5] = p  # Adding the rank\n",
    "            ranked_results_list.append(df)\n",
    "        ranked_results_list = [x for xs in ranked_results_list for x in xs]  # Flattening the list\n",
    "        ranked_results = pd.DataFrame(ranked_results_list, columns=['qid', 'docid', 'title', 'docno', 'body', 'rank', 'score', 'query'])\n",
    "    else:\n",
    "        # If the function gets a single query instead of a dataframe\n",
    "        ranked_results = ranked_results.sort_values(by=['score'], ascending=False)\n",
    "        for i in range(len(ranked_results)):\n",
    "            ranked_results.iloc[i, ranked_results.columns.get_loc('rank')] = i\n",
    "        ranked_results = ranked_results.reset_index(drop=True)\n",
    "\n",
    "    return ranked_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKW8rtLB_bWg"
   },
   "outputs": [],
   "source": [
    "# Returns a tuple of a token and raw count\n",
    "def get_tokens(index2, docno):\n",
    "    token_list, termslist = [], []\n",
    "    docid = index2.getMetaIndex().getDocument(\"docno\", docno) # Returns docid\n",
    "    pointer = index2.getDocumentIndex().getDocumentEntry(docid) # Returns DocumentIndexEntry which can be used as a pointer \n",
    "    iterator = index2.getDirectIndex().getPostings(pointer) # Returns the posting iterator\n",
    "\n",
    "    for p in iterator:\n",
    "        raw_count = p.getFrequency()\n",
    "        termid = p.getId() # Returns term id in the lexicon \n",
    "        term = index2.getLexicon().getLexiconEntry(termid).getKey() # Returns the key (the word itself)\n",
    "        token_list.append([term, raw_count])\n",
    "        termslist.append(term)\n",
    "\n",
    "    return token_list, termslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPkMtYqZr0z5"
   },
   "outputs": [],
   "source": [
    "def PRF(PRF_list, query, k, qid=None): # PRF = Pseudo Relevance Feedback \n",
    "    # Parameters:\n",
    "    # PRF_List: The Top K docs dataframe\n",
    "    # query: Query text\n",
    "    # k: The number of tokens to be added to the expanded query\n",
    "    # qid: Query ID\n",
    "    \n",
    "    all_tokens = [] # List of tokens\n",
    "    all_terms = [] # List of term (Vocabulary)\n",
    "\n",
    "    for i in range(len(PRF_list)):\n",
    "        all_tknz, all_trms = get_tokens(index2, PRF_list.iloc[i].docno) # This gets the list of tokens from the the document\n",
    "        all_tokens.append(all_tknz) # This list has tokens and raw count\n",
    "        all_terms.append(all_trms) # This list has just tokens, I will convert it to a list of terms using set()\n",
    "\n",
    "    # Flatten to have all tokens from all docs in one list\n",
    "    flatten_tokenz_list = [x for xs in all_tokens for x in xs] \n",
    "    # Flatten to have all terms (Vocab) from all docs in one list, I used set() here to remove duplicate terms\n",
    "    flatten_terms_list = set([x for xs in all_terms for x in xs]) \n",
    "\n",
    "    # List of all terms with frequency in the top K documents and number of document that has this term\n",
    "    list_of_terms_with_raw_count_number_of_docs = []\n",
    "    for term in flatten_terms_list:\n",
    "        total_raw_count, number_of_docs_that_has_term = 0, 0\n",
    "        for sublist in flatten_tokenz_list:\n",
    "            if sublist[0] == term:\n",
    "                number_of_docs_that_has_term += 1 # Getting the number of docs that has this term\n",
    "                total_raw_count += sublist[1] # Summing raw count for this token from all docs that has it\n",
    "        list_of_terms_with_raw_count_number_of_docs.append(\n",
    "            (term, total_raw_count, number_of_docs_that_has_term)\n",
    "        )\n",
    "\n",
    "    tokens_score = []\n",
    "    number_of_documents = index2.getCollectionStatistics().getNumberOfDocuments()\n",
    "    for term_info in list_of_terms_with_raw_count_number_of_docs:\n",
    "        if term_info[2] >= 3: # if token appear in 3 of the top 5 docuemnts\n",
    "            try:\n",
    "                coll_freq = index2.getLexicon()[term_info[0]].getFrequency()\n",
    "                f = coll_freq / number_of_documents\n",
    "                score = -math.log2(1 / (1 + f)) - (term_info[1] * math.log2(f / (1 + f)))\n",
    "                tokens_score.append((term_info[0], score))\n",
    "            except KeyError:\n",
    "                print(term_info[0])\n",
    "\n",
    "    sorted_by_score = sorted(tokens_score, key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    # add k tokens to the query\n",
    "    tokens_to_be_added = [term for term, score in sorted_by_score[:k]]\n",
    "\n",
    "    top_k_words = \" \".join(tokens_to_be_added) # List of tokens converted to a string \n",
    "    \n",
    "    # Return the new expanded query\n",
    "    return [qid, query + \" \" + top_k_words] if qid else query + \" \" + top_k_words \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "018NtMnOyaY9"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LongformerReranking:\n",
    "    def transform(self, query, model=MODEL, device=DEVICE):\n",
    "        query_list_length = 1\n",
    "        if isinstance(query, pd.DataFrame):\n",
    "            query_list_length = len(query.index)\n",
    "            reranked_list = longformer(bm25(query), query_list_length, query, model=model, device=device)  # Candidate list by BM25, reranking by Longformer\n",
    "        else:\n",
    "            reranked_list = longformer(bm25(query), query_list_length, model=model, device=device)  # Candidate list by BM25, reranking by Longformer\n",
    "\n",
    "        return reranked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13nchcQ_dQLf"
   },
   "outputs": [],
   "source": [
    "class LongformerRerankingPRF:\n",
    "    def transform(self, query, bm25=None, model=MODEL, device=DEVICE, k=10, K=5):\n",
    "        query_list_length = 1\n",
    "        if isinstance(query, pd.DataFrame):\n",
    "            query_list_length = len(query.index)\n",
    "            reranked_list_prf = longformer(bm25(query), query_list_length, query, model=model, device=device)\n",
    "            prf_list = []\n",
    "\n",
    "            for i in range(query_list_length):\n",
    "                query_docs = reranked_list_prf[reranked_list_prf['qid'] == str(query.iloc[i].qid)]\n",
    "                top_k_docs = query_docs.head(K)  # Getting top K documents for PRF for each query\n",
    "                expanded_q = PRF(top_k_docs, query.iloc[i].query, k, qid=topics.iloc[i].qid)  # These parameters are explained in PRF function\n",
    "                reranked_list_prf.loc[reranked_list_prf['qid'] == str(query.iloc[i].qid), \"query\"] = expanded_q[1]\n",
    "\n",
    "            # Reranking by Longformer using the expanded query\n",
    "            reranked_list_prf = longformer(reranked_list_prf, query_list_length, query, model=model, device=device)\n",
    "\n",
    "        return reranked_list_prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tfpiXn8AYyT"
   },
   "outputs": [],
   "source": [
    "Results = LongformerReranking.transform() # Takes a query in text format or dataframe (No PRF)\n",
    "ResultsPRF = LongformerRerankingPRF.transform() # Takes a query in text format or dataframe (With PRF)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Longformer Reranker.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
